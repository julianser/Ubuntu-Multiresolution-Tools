import os
import argparse
import time
import numpy
import generate_actents

# Helper function to find unique elements in list while preserving their ordering
def unique_list_elements(l):
  output = []
  for x in l:
    if x not in output:
      output.append(x)
  return output

def parse_args():
  parser = argparse.ArgumentParser()
  parser.add_argument("true_dialogue_actents", type=str, default="", help="Ground truth dialogue activity-entity representations")
  parser.add_argument("model_dialogues", type=str, default="", help="Dialogues generated by model")

  parser.add_argument("--do_not_compute_model_dialogue_actents", action='store_true', help="Use this option if model dialogues are already given as activity-entity representations")

  parser.add_argument("--skip_dialogues_without_activities", action='store_true', help="If enabled, all ground truth test responses without activities will be excluded from the evaluation procedure. Otherwise, the procedure will always assign zero precision/recall/f1 activity metrics to test responses without activities (e.g. with the \"none_activity\")")

  return parser.parse_args()

if __name__ == "__main__":
    args = parse_args()

    # Dataset variables
    activity_postfix = '_activity'
    activity_postfix_len = len(activity_postfix)
    none_activity = 'none_activity'

    entity_postfix = '_entity'
    entity_postfix_len = len(entity_postfix)

    tense_postfix = '_tenses'
    tense_postfix_len = len(tense_postfix)

    cmd_postfix = '_cmd'
    cmd_postfix_len = len(cmd_postfix)

    compute_model_dialogue_actents = True
    if args.do_not_compute_model_dialogue_actents:
        compute_model_dialogue_actents = False


    # First, estimate activity-entity representations for generated dialogues
    if compute_model_dialogue_actents:
        print ' Computing dialogue activity-entity representations for model dialogues...'

        # Create temporary directory for files
        if not os.path.exists('tmp'):
            os.makedirs('tmp')

        file_tmp_a = 'tmp/' + str(int(time.time())) + '_a_tmp.txt'
        file_tmp_b = 'tmp/' + str(int(time.time())) + '_b_tmp.txt'
        file_model_dialogue_actents = 'tmp/' + str(int(time.time())) + 'dialogue_actents_tmp.txt'

        # Preprocess dialogues
        generate_actents.process_dialogues(args.model_dialogues, file_tmp_a, file_tmp_b)

        # Compute dialogue activity-entity representations
        generate_actents.process_actents(args.model_dialogues, file_tmp_b, file_model_dialogue_actents)
    else:
        print ' Model dialogue activity-entity representations are assumed given as input...'
        file_model_dialogue_actents = args.model_dialogues

    # Load dialogue activity-entity representations
    true_dialogue_actents_lines = open(args.true_dialogue_actents, 'r').readlines()
    model_dialogue_actents_lines = open(file_model_dialogue_actents, 'r').readlines()

    assert len(true_dialogue_actents_lines) == len(model_dialogue_actents_lines)

    # Activity metrics
    activity_precisions = []
    activity_recalls = []
    activity_f1s = []

    # Entity metrics
    entity_precisions = []
    entity_recalls = []
    entity_f1s = []

    # Tense metrics
    tense_accuracies = []

    # Command metrics
    cmd_accuracies = []

    true_examples_with_entities = 0
    model_examples_with_entities = 0

    # Evaluate dialogue activity-entity representations
    for i in range(len(model_dialogue_actents_lines)):
        if i % 1000 == 0:
            print ' Evaluating example ' + str(i) + ' / ' + str(len(model_dialogue_actents_lines))

        true_dialogue_actents_example = unique_list_elements(true_dialogue_actents_lines[i].strip().split())
        model_dialogue_actents_example = unique_list_elements(model_dialogue_actents_lines[i].strip().split())

        # If the option 'skip_dialogues_without_activities' is enabled,
        # skip the example if the ground truth dialogue does not contain any activity
        if args.skip_dialogues_without_activities:
            if none_activity in true_dialogue_actents_example:
                continue

        # Compute precision, recall and F1 score for activities
        activity_in_true = 0
        activity_true_positives = 0

        for act in true_dialogue_actents_example:
            if len(act) > activity_postfix_len:
                if act[-activity_postfix_len:] == activity_postfix:
                    if not act == none_activity:
                        activity_in_true += 1

                        if act in model_dialogue_actents_example:
                            activity_true_positives += 1
                
        activity_in_model = 0
        for act in model_dialogue_actents_example:
            if len(act) > activity_postfix_len:
                if act[-activity_postfix_len:] == activity_postfix:
                    if not act == none_activity:
                        activity_in_model += 1

        activity_false_positives = activity_in_model - activity_true_positives
        activity_false_negatives = activity_in_true - activity_true_positives

        if activity_true_positives > 0:
            activity_precision = float(activity_true_positives)/float(activity_true_positives+activity_false_positives)
            activity_recall = float(activity_true_positives)/float(activity_true_positives+activity_false_negatives)
        else:
            activity_precision = 0.0
            activity_recall = 0.0

        if activity_precision + activity_recall > 0.00000001:
            activity_f1 = 2.0*(activity_precision*activity_recall)/(activity_precision+activity_recall)
        else:
            activity_f1 = 0.0

        activity_precisions.append(activity_precision)
        activity_recalls.append(activity_recall)
        activity_f1s.append(activity_f1)

        # Compute precision, recall and F1 score for entities
        entity_in_true = 0
        entity_true_positives = 0

        for act in true_dialogue_actents_example:
            if len(act) > entity_postfix_len:
                if act[-entity_postfix_len:] == entity_postfix:
                    entity_in_true += 1

                    if act in model_dialogue_actents_example:
                        entity_true_positives += 1
                
        entity_in_model = 0
        for act in model_dialogue_actents_example:
            if len(act) > entity_postfix_len:
                if act[-entity_postfix_len:] == entity_postfix:
                    entity_in_model += 1

        if entity_in_true > 0:
            true_examples_with_entities += 1

        if entity_in_model > 0:
            model_examples_with_entities += 1

        entity_false_positives = entity_in_model - entity_true_positives
        entity_false_negatives = entity_in_true - entity_true_positives

        if entity_true_positives > 0:
            entity_precision = float(entity_true_positives)/float(entity_true_positives+entity_false_positives)
            entity_recall = float(entity_true_positives)/float(entity_true_positives+entity_false_negatives)
        else:
            entity_precision = 0.0
            entity_recall = 0.0    

        if entity_precision+entity_recall > 0.00000001:
            entity_f1 = 2.0*(entity_precision*entity_recall)/(entity_precision+entity_recall)
        else:
            entity_f1 = 0.0

        entity_precisions.append(entity_precision)
        entity_recalls.append(entity_recall)
        entity_f1s.append(entity_f1)

        # Compute accuracy for tenses
        true_tense = ''
        for act in true_dialogue_actents_example:
            if len(act) > tense_postfix_len:
                if act[-tense_postfix_len:] == tense_postfix:
                    true_tense = act
                    break

        if true_tense in model_dialogue_actents_example:
            tense_accuracies.append(1.0)
        else:
            tense_accuracies.append(0.0)

        # Compute accuracy for commansd
        true_cmd = ''
        for act in true_dialogue_actents_example:
            if len(act) > cmd_postfix_len:
                if act[-cmd_postfix_len:] == cmd_postfix:
                    true_cmd = act
                    break

        if true_cmd in model_dialogue_actents_example:
            cmd_accuracies.append(1.0)
        else:
            cmd_accuracies.append(0.0)

    # Compute means and standard deviations for activities
    q = 1.96/numpy.sqrt(len(activity_precisions))

    activity_precisions = numpy.asarray(activity_precisions, dtype='float32')
    activity_recalls = numpy.asarray(activity_recalls, dtype='float32')
    activity_f1s = numpy.asarray(activity_f1s, dtype='float32')

    print 'Activity Precision: ' + str(numpy.mean(activity_precisions)) + ' +/- ' + str(q*numpy.std(activity_precisions)) + ' (' + str(numpy.std(activity_precisions)) + ')'
    print 'Activity Recall: ' + str(numpy.mean(activity_recalls)) + ' +/- ' + str(q*numpy.std(activity_recalls)) + ' (' + str(numpy.std(activity_recalls)) + ')'
    print 'Activity F1: ' + str(numpy.mean(activity_f1s)) + ' +/- ' + str(q*numpy.std(activity_f1s)) + ' (' + str(numpy.std(activity_f1s)) + ')'

    # Compute means and standard deviations for entities
    entity_precisions = numpy.asarray(entity_precisions, dtype='float32')
    entity_recalls = numpy.asarray(entity_recalls, dtype='float32')
    entity_f1s = numpy.asarray(entity_f1s, dtype='float32')


    print 'Entity Precision: ' + str(numpy.mean(entity_precisions)) + ' +/- ' + str(q*numpy.std(entity_precisions)) + ' (' + str(numpy.std(entity_precisions)) + ')'
    print 'Entity Recall: ' + str(numpy.mean(entity_recalls)) + ' +/- ' + str(q*numpy.std(entity_recalls)) + ' (' + str(numpy.std(entity_recalls)) + ')'
    print 'Entity F1: ' + str(numpy.mean(entity_f1s)) + ' +/- ' + str(q*numpy.std(entity_f1s)) + ' (' + str(numpy.std(entity_f1s)) + ')'

    # Compute means and standard deviations for time tenses and commands
    t_acc = numpy.mean(tense_accuracies)
    print 'Tense Accuracy: ' + str(t_acc) + ' +/- ' + str(q*t_acc*(1.0-t_acc))

    c_acc = numpy.mean(cmd_accuracies)
    print 'Command Accuracy: ' + str(c_acc) + ' +/- ' + str(q*c_acc*(1.0-c_acc))


    # More stats
    print 'Model examples with entities:', model_examples_with_entities
    print 'Ground truth examples with entities:', true_examples_with_entities

